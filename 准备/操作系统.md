* 作业与进程的区别

  1. 前者是由用户提交，后者是由系统自动生成；前者以用户任务为单位，后者是操作系统控制的单位.
  2. 作业 = 程序 + 数据 + 说明书, 进程 = 程序 + 数据 + PCB
  3. 一个作业可以分为多个进程来完成

* 进程与线程

  1. 进程是资源分配的最小单位, 线程是CPU调度的最小单位
  2. 一个进程下可包含1至多个线程
  3. 一个进程有独立的地址空间, 故进程间不能共享数据, 该进程下的多个线程共享该进程的地址空间, 但线程也有自己独立的堆栈和局部变量. 线程崩溃会带崩进程下的其他线程, 进程则不会. 进程相比线程, 切换也会消耗更多资源

* 调度

  1. 分类
     1. 作业调度(高级调度): 把作业从外存调入内存
     2. 进程调度(低级调度): 进程获得处理器调度
  2. 调度算法
     1. 当多个进程(作业)要使用有限资源时, 必须按一定规则选择进程(作业)来占用资源, 以避免饥饿与死锁
     2. 先来先服务算法: 利于计算密集型, 非抢占式, 不会引起饥饿
     3. 短作业优先算法: 利于短作业, 非抢占式, 会引起饥饿
     4. 优先权算法
        1. 静态优先权算法, 非抢占式, 会饥饿
        2. 动态优先权算法, 非抢占式, 不会饥饿, 权值=(已等待时间+服务时间)/服务时间
     5. 时间片轮转算法
        1. 抢占式, 不会饥饿
        2. 进程按照先来先服务的顺序进入队列, 每次调度将资源分给队首进程, 执行完时间片后, 将该进程放置队尾. 通过上下文切换, 移动至第二个进程. 进程可以提前释放时间片, 比如进入阻塞.
        3. 时间片选取很关键, 过大退化成先来先服务算法, 过短则陷入频繁切换, 退化为短作业优先算法
     6. 多级反馈队列算法
        1. 抢占式, 不会饥饿
        2. 多个就绪队列, 优先级依次降低, 时间片依次增大. 使得I/O较多的进程, 快速执行完. 计算较多的进程, 逐渐给予更多时间片.
        3. 当前进程在运行完时间片后, 会被塞入下级队列尾部.
        4. k级队列为空时, 才能运行k+1队列中的任务, 且当优先级高队列出现任务, 当前任务移到队列末尾, 执行优先级高队列中的作业.

* 饥饿

  1. 定义: 一个作业长时间得不到执行

* 死锁

  1. 定义: 多个进程因竞争资源而导致的一种僵局, 如无外力作用, 这些进程都会无法继续执行

  2. 原因: 竞争资源 + 非法的进程推进顺序

  3. 死锁可以用哲学家进餐问题来描述

  4. 产生死锁的四个必要条件

     1. 互斥: 资源同时只可被一个进程占用
     2. 请求和保持: 某进程因请求资源时被阻塞, 对已获得的资源不放弃
     3. 不剥夺: 资源不可被抢占
     4. 环路等待: 发生死锁时, 必有进程-资源环形链

     

  5. 处理死锁:

     1. 预防死锁: 破坏死锁的四个必要条件之一. 目前主要是避免死锁, 而不是预防死锁, 死锁预防需要消耗大量资源

     2. 避免死锁: 寻找系统安全状态, 在资源分配前, 寻找一个进程推进的安全序列, 找到就执行分配并推进, 未找到就处于不安全状态

        1. 银行家算法定义

           操作系统是银行家, 资源就是钱, 定义如下4个数组, 并存在max = need + allocation这样的关系

           available[m]: 现有m个不同的可分配资源

           max[n] [m]: n个进程对m个资源的总需求量

           allocation[n] [m]: n个进程对m个资源的已分配量

           need[n] [m]: n个进程对m个资源的尚需量

        2. 银行家算法描述

           request[i] [j]=k, i进程需要k个j资源

           检查: 如果need[i] [j] >= request[i] [j], 下一步, 否则报错. 如果request[i] [j] <= available[j], 给予预分配, 否则等待.

           预分配: need[i] [j] -= request[i] [j], allocation[i] [j] += request[i] [j],  available[j] -= request[i] [j]

           检查: 若预分配后系统仍处于安全状态, 则给予正式分配

     3. 检测死锁: 资源分配图, 通过简化可去除所有的边, 即为没有死锁状态, 详见https://blog.csdn.net/lierming__/article/details/79000632

     4. 解除死锁:

        1. 资源剥夺法: 挂起进程, 抢占资源
        2. 进程撤销法: 撤销进程, 剥夺资源

* 编译

  1. 编译器: 将源码转成二进制的机器码. 比如gcc, javac
     1. 预处理: 替换宏定义和头文件地址
     2. 编译: 转为汇编
     3. 汇编: 转为二进制机器码, 此步将产生目标文件
     4. 链接: 分为静态链接与动态连接
        1. 静态连接: 载入代码时就会确定代码地址, 将库一起打包入可执行文件, 因此可执行文件很大, 不方便库升级, 不共享库, 耗内存.
        2. 动态链接: 调用时才确定代码地址, 共享库, 内存占用低, 初始化快, 执行慢.
  2. 复杂项目的编译分成三部分:
     1. configure: 由autoconf产生, 包含配置信息, 会产生makefile, 即编译顺序文件
     2. make: 编译
     3. make install: 安装

* 内存

  1. 相关问题
     1. 内存碎片: 不能供进程使用的内存里的小分区
        1. 内部碎片: 已分配且未使用
        2. 外部碎片: 未分配且不宜使用
     2. 内存溢出: 程序要求分配的内存超出系统能给的
     3. 内存泄露: 程序在申请内存后未释放已申请的内存, 一次没问题, 但是多了会造成内存泄露堆积, 最终导致内存溢出.
  2. 分页
     1. 一个进程被分为若干固定大小的区域, 被称为页. 内存分为若干个物理块, 称为"块"或"页框"
     2. 页和页框大小相等, 由操作系统控制分割
     3. 分页是为了实现存储的非连续, 避免内存碎片(外部碎片)
     4. 页是信息的物理单位, 页大小固定
     5. 页表: 每个进程会有一个页表, 指明该进程中某页对应在内存中的页框. 页表第一列为页号, 第二列为页框号. 处理器会将程序的逻辑地址(页号+偏移量), 转为内存的物理地址(页框号+偏移量)
  3. 分段
     1. 一个进程被分为若干大小不等的区域, 被称为段.
     2. 每段存储一组在逻辑上相对完整的信息, 由编译器控制分割.
     3. 分段是为了更好的共享, 多个进程可以共享一个段, 相比分页有较高的内存利用率
     4. 段是信息的逻辑单位, 段大小随机
     5. 段表: 类似于页表
  4. 虚拟内存
     1. 具有置换功能, 能在逻辑上对内存扩充的一种存储系统
     2. 内存置换算法:
        1. 先进先出
        2. 最近最久未使用 (LRU)
        3. clock算法

* 并发控制

  1. 并发执行下, 为保证隔离性, 多事务间不互相影响.

  2. 一般并发控制指的就是数据库的并发控制, 实现并发控制主要分为乐观锁与悲观锁.

  3. 悲观锁

     1. 使用读锁/写锁, 最好需要依靠数据库提供的锁机制, 也只有数据库提供了锁机制, 才能保证其不被外部系统所修改, 因为即使本系统实现了锁, 外部系统仍可修改.
     2. 适合数据争用激烈的情况
     3. 悲观锁可能会导致死锁

  4. 乐观锁

     1. 在数据提交更新时, 才对数据检测是否冲突, 一般通过数据版本或CAS实现.
     2. 适合数据争用少的情况

  5. 数据快照

     类似于MySQL的MVCC

* 内核态与用户态

  1. 内核态: 可以访问系统资源, 比如CPU, 内存, 网络, 外设
  2. 用户态: 只能访问进程自己的资源, 无法访问系统资源
  3. 用户态需要访问系统资源时, 需要CPU切到内核态, 读取资源后再切回用户态. 中间涉及堆栈上下文的切换, 为避免频繁切换, 有了"用户缓冲区"和"系统缓冲区".
  4. 当用户进程需要从"磁盘/网络"中读取数据时, 系统会将"系统缓冲区"的数据复制到"用户缓冲区". 若"系统缓冲区"中没有对应数据, 系统会将当前进程挂起, 处理其他进程. 等数据到达"系统缓冲区"后, 系统将数据拷贝至"用户缓冲区", 然后才会通知进程, 注意不同IO模型方式不同.

* 五种IO模型, IO即磁盘/网络读写

  1. c10k
     一台计算机实现10000台客户端的连接, 并处理对应的请求. 一个进程处理一个连接, 会消耗过多资源. 所以要一个进程处理多个连接, 即IO多路复用, 目前通过IO多路复用已实现c10k.

  2. 五种IO模型 (参考自https://zhuanlan.zhihu.com/p/54580385)

     1. 所有的IO模型都分为两阶段, 前四个模型, 第二阶段复制数据阶段都是阻塞的.
        1. 等待系统将数据准备好, 即等待数据从网卡/磁盘复制到"系统缓冲区"
        2. 将数据从"系统缓冲区"复制到"用户缓冲区"
     2. 阻塞式IO, 第一阶段"请求进程"调用receive, 一直阻塞至第二阶段完成
     3. 非阻塞IO, 第一阶段"请求进程"不停调用receive, receive立即返回异常. 直至"数据已备好"后, "请求进程"再调用receive会阻塞至第二阶段完成
     4. IO多路复用(即事件驱动), 第一阶段"请求进程"调用select, 并阻塞至"数据准备好". 第二阶段"请求进程"发起receive, 阻塞至拷贝完成. 虽然看起来"请求进程"都是阻塞, 但是服务器内核可以同时监听select负责的多个套接字, 服务器效率非常高
     5. 信号驱动IO, 第一阶段"请求进程"向内核注册信号后, 不阻塞. 当"数据准备好"后, 内核通过信号通知"请求进程", "请求进程"调用receive, 阻塞取得数据
     6. 异步IO, 第一阶段"请求进程"发起receive, 不阻塞. 当第二阶段数据拷贝完后, 内核会通过回调通知"请求进程".

  3. nginx是事件驱动服务器的代表, 适合IO密集型服务, 使用的是epoll; Apache是线程服务器的代表, 适合计算密集型服务(apache存疑)

  4. I/O多路复用 (select, poll, epoll)

     1. select

        1. 原理

           1. select通过内核来监视一个由多个文件描述符(fd)组成的数组. 当select返回后, 数组中就绪的文件描述符会被内核修改标记位, 进程便可以通过遍历数组, 来获得这些文件描述符并从而进行后续的读写操作.
           2. 进程会指定内核监听哪些文件描述符的哪些事件, 当没文件描述符所监听的事件发生时, 进程被阻塞, 当一个或者多个文件描述符事件发生时, 进程则被唤醒.
           3. 文件描述符数组: 位图(bitmap), 最大一般为1024位, 即最大可监听1024个文件描述符. 当有事件发生时, 对应的位会被标记为1. 当下一次监听时, 位图需全部置为0.

        2. select被调用时的过程

           1. 上下文切换, 将用户态切换为内核态, 并将fd数组从用户空间复制到内核空间
           2. 内核遍历fd数组, 查看这些文件描述符对应事件是否发生
           3. 如果这些文件描述符无对应事件发生, 进程将阻塞. 当设备驱动产生中断或者timeout时间后, 进程唤醒并再次进行遍历. 持续该过程直至有事件发生
           4. 内核标记发生事件的fd, 并将fd从内核空间复制到用户空间, 并从内核态切换为用户态

        3. select函数

           1. 定义: select用来监视多个文件描述符, 当文件描述符所对应事件状态不改变时, select会阻塞; 当某个文件描述符所对应事件状态改变后, 会返回三个列表.

           2. 案例

              readable_list, writeable_list, execable_list = select.select(read_list, write_list, exce_list, timeout)
              当read_list的fd满足可读条件时, 则将发生变化的fd添加到readable_list中
              当write_list的fd满足可写条件时, 则将发生变化的fd添加到writeable_list中
              当exce_list的fd发生错误时, 则将该发生错误的fd添加到execable_list中

        4. select缺点

           1. 单个进程能够监视的fd数量存在限制, 在linux上为1024
           2. 当fd数组很大时, 因每次调用select都需要把fd数组从用户空间拷贝到内核空间, 所以开销很大
           3. 当fd数组很大时, 内核对fd数组的遍历浪费时间



     2. poll
        1. 原理
           1. 结构
              struct pollfd {
                int fd;  # 文件描述符
                short events;  # 该文件描述符注册的事件集合
                short revents;  # 该文件描述符状态发生变化的事件集合
              }
           2. poll通过内核监视多个pollfd组成的数组, 当任一所监听的pollfd变化时, revents会被标记并返回. 且下一次监听时, events不用重新置位. poll本质上和select无区别, 只是没有最大连接数的限制, 原因是它基于链表存储. 
        2. poll缺点
           1. 当fd数组很大时, 因为每次调用poll都需要把pollfd数组从用户空间拷贝到内核空间, 所以开销很大
           2. 当fd数组很大时, 内核对pollfd数组的遍历浪费时间


     3. epoll
        1. epoll的原理及改进
           1. 结构
              struct epollfd {
                  int fd;  # 文件描述符
                  short events;  # 该文件描述符注册的事件集合
              }
           2. 在freeBSD系统上没有epoll, 请使用kqueue. kqueue与epoll的不同之处: kqueue的一个fd的read/write事件需要分开注册, 而epoll则是一个fd一次注册read/write事件.
           3. 对于select第一个缺点, epoll所支持的最大fd数量是系统中最大可打开文件的数目, 一般该数目和系统内存有较大关系. 
           4. 对于select第二个缺点, 使用了内存映射(mmap)技术, 即调用epoll_ctl函数时, 每次注册新的事件到epoll时, 会把所有的fd拷贝进内核, 而不是在epoll_wait的时候重复拷贝, 保证了每个fd在整个过程中只会拷贝1次, 避免了文件描述符在系统调用时复制的开销.
           5. 对于select第三个缺点, epoll采用基于事件的就绪通知方式. 即调用epoll_ctl函数时, 将为每个fd指定一个回调函数, 当设备就绪时, 就会调用这个回调函数. 而这个回调函数会把就绪的fd加入一个就绪链表. 当调用epoll_wait函数时, 将从就绪链表中返回就绪的fd, 且对应进程会得到通知. 调用epoll_wait获得就绪文件描述符时, 返回的不是实际的描述符, 而是一个代表就绪描述符数量的值. 你需要去epoll指定的链表中依次取得相应数量的文件描述符即可.
        2. 通知模型
           1. 水平触发(LT)
              1. 文件描述符上有数据变化时, 触发一个事件. 可以只读该事件有关的一部分数据, 未读完则下次检查时会再触发事件来通知
              2. 优点是稳定可靠, 缺点是当就绪的文件描述符过多时效率低
           2. 边缘触发(ET)
              1. 文件描述符上有数据变化时, 触发一个事件. 需要一次读完该事件有关的数据, 否则之后不会再触发事件来通知.
              2. 优点是高效, 缺点是不可靠, 实现复杂
           3. select, poll仅支持水平触发; epoll支持水平触发和边缘触发, 默认采用水平触发; nginx采用的是边缘触发. 
              参考: https://blog.csdn.net/fengxinlinux/article/details/75331567

* 零拷贝 (参考自https://juejin.im/post/6844903949359644680)

  1. 当用户进程通过网络发送磁盘数据时, 依次调用read和send.
     1. 调用read时, 首先内核会检查"系统缓冲区"有无缓存, 若没有, 会通过DMA将数据从磁盘拷贝到"系统缓冲区". 然后通过CPU将数据从"系统缓冲区"拷贝到"用户缓冲区".
     2. 调用send时, 通过CPU将数据从"用户缓冲区"拷贝到套接字的"系统缓冲区", 再由套接字的"系统缓冲区", 通过DMA拷贝到网卡中, 发送出去.
     3. 总体上经过4次内核态与用户态的上下文切换, 2次CPU调用, 2次DMA调用

  2. 零拷贝优点
     1. 减少数据在"用户缓冲区"与"系统缓冲区"间的拷贝
     2. 减少数据拷贝时, "用户态"与"内核态"的上下文切换
  3. 实现方式
     1. 用mmap+send代替的read+send, mmap可将指定的"系统缓冲区"对用户进程共享, 从而避免CPU将数据从"系统缓冲区"拷贝到"用户缓冲区", 因此也不存在send时CPU将数据再从"用户缓冲区"拷贝到"系统缓冲区", 但会多1次从"系统缓冲区"到套接字的"系统缓冲区"的CPU拷贝, 故整体少了1次CPU拷贝.  总体上4次上下文切换, 1次CPU调用, 2次DMA调用
     2. 用sendfile代替read+send, 也是减少1次CPU拷贝, 但因为数据可以直接在内核空间传输, 故减少2次上下文切换. 总体上2次上下文切换, 1次CPU调用, 2次DMA调用
     3. 用splice代替read+send, 通过在"系统缓冲区"与套接字的"系统缓冲区"间建立管道, 完全避免了CPU拷贝. 总体上2次上下文切换, 0次CPU调用, 2次DMA调用

* 高并发系统

  1. 服务扩展

     1. 横向扩展(水平扩展): 用更多的节点支持更多的请求
     2. 纵向扩展(垂直扩展): 提升单节点的处理能力

  2. 高并发指标

     响应时间, 每秒请求率(QPS), 吞吐量, 并发用户数

  3. 保护高并发系统
     缓存, 限流, 降级

