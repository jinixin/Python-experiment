* 多个事务同时操作带来的问题

  ​		多个事务并发执行, 由此引出隔离性的问题

  1. 脏读

     一个事务更新了数据, 另个事务读取了同份数据, 但前份数据回滚了

  2. 不可重复读

     一个事务中两次查询的数据不一致, 因为之间另一事务提交了更新数据

  3. 幻读

     一个事务中两次查询到的数据笔数不一致, 因为之间另一事务插入了数据

     

* 事务隔离级别

  1. 读取未提交内容 (read uncommitted)

     事务A可以读到事务B未提交的修改. 会导致脏读, 不可重复读, 幻读

  2. 读取提交内容 (read committed)

     一般数据库默认隔离级别. 事务A读取了数据, 事务B对数据修改并提交了, 事务A再读时会读到修改的数据. 会不可重复读, 幻读

  3. 可重读(repeatable read)

     MySQL默认隔离级别. 事务A读取了数据, 事务B对数据修改并提交了, 但事务A再读时还是会读到原来的数据. 会幻读 ( MySQL中已解决).

  4. 可串行: 对事务排序执行. 无问题, 但低并发

      

* MySQL设置隔离级别

  1. 会话(session)指一次数据库连接, 事务(transaction)指一个操作单元, 要么成功, 要么失败. 一个会话中可以有多个事务.
  2. set [ session | global |  无] transaction isolation level [ read uncommitted | read commited | repeatable read | serializable ]
     1. global: 对之后所有的会话有影响
     2. session: 对当前会话之后所有的事务有影响
     3. 无: 对当前会话中下一个事务有影响
  3. ACID (事务的四大特性)

     1. 事务: 数据库一系列SQL作为一个统一整体执行, 要么都成功, 要么都失败
     2. 原子性: 要么全部成功, 要么全部失败
     3. 一致性: 系统从一个正确状态到另一个正确状态
     4. 隔离性: 一个事务提交前, 其的修改对其他事务不可见, 有四个级别
     5. 持久性: 事务提交后的修改是持久的

* redo log 和 undo log 和 binlog

  1. MySQL分层

     1. 接入层 -> MySQL服务层 -> 存储引擎层 -> 系统文件层
     2. 接入层: 不同语言客户端通过MySQL协议与MySQL服务器连接通信, 该层负责权限验证, 连接池管理
     3. MySQL服务层: SQL解析器, SQL优化器, 缓存
     4. 存储引擎层, mysql服务器中对数据的读取和写入是交给存储引擎来处理的
     5. 系统文件层: 保存数据, 索引, 日志

  2. binlog (归档日志)

     1. 逻辑日志, binlog是MySQL Server的日志, 用于主从同步, 数据复制 (如MySQL至ES)

     2. 从库会开启"IO线程", 不断读取主库binlog, 并写入中继日志(relay log). 从库"SQL线程"会读取并顺序执行中继日志, 与主库保持一致

     3. binlog三种模式

        1. statement模式

           1. 记录数据修改的SQL (增删改)
           2. 优点是binlog量很小, 缺点是函数很难同步, 比如last_insert_id()

        2. row模式

           1. 记录每一行记录在修改前后的数据
           2. 优点是避免statement模式下函数无法同步的问题, 缺点是binlog量很大

        3. mixed模式

           混用statement模式与row模式

  3. 事务日志

     1. redo log与undo log是innodb引擎的日志, 用于实现事务

     2. redo log用于前滚操作, 保证事务的持久性. undo log用于回滚操作与MVCC, 保证事务的原子性, 一致性

     3. 前滚与回滚

        1. 前滚

           未完全提交的事务, 即该事务已被commit, 但该事务所涉及的数据中只有一部分落盘, 另一部分还在内存中. 此时数据库崩溃, 恢复时需要利用前滚, 使得该事务涉及的数据完全落盘

        2. 回滚

           未提交的事务, 即该事务未被commit

     4. redo log (重做日志)

        1. 物理日志, 记录某个数据页上的所有修改, 用于崩溃处理

        2. 事务提交时, MySQL将事务修改的所有数据落盘来保证持久性. innodb是以页为单位与磁盘交互的. 事务提交时, 将所有修改落盘, 会影响性能, 故产生redo log. 这种对记录修改先写日志, 再写磁盘的技术, 就是WAL技术.

        3. 有了redo log, innodb就能保证提交的记录永不丢失, 这种能力叫做crash-safe

        4. redo结构

           1. redo log包括内存中的"redo log 缓冲区"与磁盘上的"redo log 文件". SQL执行后, 数据页上的修改先入"redo log 缓冲区", 再入磁盘上的"redo log 文件". 缓冲区就是用来提高性能, 减少IO. 缓冲区刷新到磁盘有三种时机: 每秒/事务提交时/日志缓存可用空间少于一半时.
           2. redo log占用的空间是固定的, 其通过循环队列的方式将redo log里的数据修改落盘.

        5. 并发的多个事务共享redo log, 当一个事务提交时, redo log会落盘. 此时会将其他未提交事务的日志也一并落盘.

        6. 二阶段提交

           1. redo log与binlog必须保持一致, 否则两日志不一致最终会导致主从不一致. 由此引出二阶段提交, 其可以保证redo log与binlog一致. 二阶段提交即是将redo log的写入拆成prepare与commit两个阶段. 二阶段提交是经典的分布式问题
           2. 事务在提交时, 分为"时间点1" -> "prepare阶段" -> "时间点2" -> "commit阶段" -> "时间点3"
           3. prepare阶段, 当前事务中新生成的redo log会被刷入磁盘, redo log中将该事务标记为prepare状态
           4. commit阶段, 释放innodb锁, binlog刷入磁盘, redo log中将该事务标记为commit状态
           5. 故障模拟
              1. 时间点1故障: redo log与binlog都在内存中, 重启后相当于事务回滚
              2. 时间点2故障: redo log已落盘,  redo log为prepare阶段, 但binlog不确定. 需判断binlog是否完整, 完整则redo log至为commit, 提交事务, 否则回滚事务
              3. 时间点3故障: redo log与bin log都在磁盘中, 无影响

        7. 崩溃恢复

           数据恢复时, 会重做redo log中所有记录, 包括未提交的事务, 然后通过undo log回滚那些未提交的事务

     5. undo log (回滚日志)

        1. 逻辑日志, 存放记录被修改前的值, 如果修改出现异常, 可使用undo log来回滚, 保证事务的原子性与一致性. undo log还是实现多版本并发控制的关键

        2. 一条insert, 对应一条delete的undo log; 一条update/delete, 对应一条相反的update的undo log

        3. undo log被看作数据, undo log也会被记录到redo log中, 这样就保证了undo log的持久化

        4. undo log/redo log/事务

           假设有字段为key, val的数据表. key=A时, val=1; key=B时, val=2. 现在把key=A时, 值修改为10; key=B时, 值修改为20

           1) 事务开始

           2) 记录A=1到undo log

           3) 修改A=10 (内存)

           4) 记录A=10到redo log

           5) 记录B=2到undo log

           6) 修改B=20 (内存)

           7) 记录B=20到redo log

           8) 事务提交 (redo log写入磁盘)

  4. MVCC

     1. MVCC即"多版本并发控制". 通过维护数据的多个历史版本, 来解决并发访问下数据一致性的问题. 读操作时, 读到的数据是某个历史版本, 写操作时, 不覆盖已有数据, 而是创建一个新版本. 不同的事务仅看到自己特定版本的数据
     2. 与MVCC相对应的是"锁的并发控制", MVCC的并发能力远优于"锁的并发控制" (悲观锁)
     3. 实现
        1. 表中每行记录后面都有两个隐藏字段: trx_id和roll_pointer
        2. trx_id: 创建该行时的事务id (事务id是不停自增的)
        3. roll_pointer: 回滚指针, 创建该行时的undo log地址
        4. 当该行记录被多次修改后, 该行记录的undo log就会串联起来形成一个"版本链". 如果隔离级别是"读取未提交内容", 查询时只要读取版本链中最新版本记录即可; 如果隔离级别是"读取已提交内容"或"可重复读", 则需要遍历"版本链"中每条记录, 根据trx_id判断该记录对当前事务是否可见, innodb中通过readview实现该功能, "读取已提交内容"和"可重复读"生成readview的时机不同, 造成了不同的隔离效果.

* 锁

  1. 表锁, 锁定粒度大, 获取/释放锁速度快, 低并发, 无死锁
  2. 行锁, 锁定粒度小, 获取/释放锁速度慢, 高并发, 易死锁
  3. 页锁, MySQL特有
  4. 意向锁, innodb特有

* 表锁

  1. 共享锁 (读锁)

     会阻塞其他事务对同一表的写, 不阻塞读

     lock tables 表名 read

  2. 排他锁 (写锁)

     会阻塞其他事务对同一表的读和写

     lock tables 表名 write

* 行锁

  1. innodb的行锁是通过对索引上的索引项加锁实现的, 因此只有通过索引来检索(where)数据, 才会用行锁, 否则将自动升级为表锁.

  2. 当检索数据的条件不是相等而是范围, 在请求锁时, innodb也会对不存在的数据加锁, 即间隙锁, 目的是防止幻读

  3. 执行update, delete. insert前会自动给涉及的数据集加写锁, select不会加任何锁

      

  4. 共享锁 (读锁)

     会阻塞其他事务对同一行的写, 不阻塞读

     select * from 表名 where 条件 lock in share mode

     

  5. 排他锁 (写锁)

     会阻塞其他事务对同一行的读和写

     select * from 表名 where 条件 for update

     

* 意向锁

  1. innodb特有的表级锁, 其他事务通过其可知目标表上是否有事务正在占用, 而不必一行行检查是否存在锁

  2. 意向锁之间不互斥, 意向锁与行级锁之间不互斥, 意向锁与表级锁之间会互斥(除了共享意向锁和共享锁兼容)

  3. 意向共享锁

     事务在加行级共享锁之前, 会自动先向表加共享意向锁, 成功后再增加对应行锁, 否则阻塞

  4. 意向排他锁

     事务在加行级排他锁之前, 会自动先向表加排他意向锁, 成功后再增加对应行锁, 否则阻塞

* 死锁

  1. 原因

     innodb中, 事务中的锁是逐步获得的, 只有在commit和rollback时锁才会被释放. 当两个事务都需要对方持有的锁才能继续推进时, 就会造成死锁

  2. 解决

     1. 以相同顺序来访问表

     2. 事务开始时一次性锁定所需资源

     3. 如果要更新, 直接获取写锁, 不获取读锁. 当表比较大, 需要更新大部分数据, 直接用表锁.

     4. 在锁不变的情况下, 尽可能减少锁定时间, 提高并发

* 记录

  1. 行格式: 每条记录存储的格式称为行格式, 一般格式为: "可变字段长度列表,null值列表,记录的头信息,每列的具体数据".
  2. 头信息
     1. delete_mask位用来标记该记录是否被删除
     2. record_type位表示记录类型 (0为普通记录, 1为目录项记录, 2为最小记录, 3为最大记录)
     3. next_record位指向下一条记录
  3. 删除记录: 改变该记录上家的next_record, 并把该记录中头信息的delete_mask标记为1即可
  4. 行溢出: 当记录中数据太多时, 会将数据存到其他页中

* 页

  1. 概述: 数据以页为单位, 作为内存和磁盘间数据交换的单位, 页的大小为16KB, 一个页中至少存储两条记录
  2. 分类
     1. 页可以分为数据页和目录项页, 数据页存储数据, 目录项页存储页编号
     2. 目录项页和数据页的结构一致, 但只有两列: "主键值, 页号". 记录的头信息中next_record指向顺序中的下一个页. 数据页中记录的头信息中每行record_type都是0, 目录项页中记录的头信息中每行record_type都是1
  3. 结构
     1. 页中
        1. 记录在页中是按照主键由小到大顺序存为单链表, 被删记录也被连成一条链表
        2. 页会被分为多个组, 每组中拥有1~8条记录, 每组的最后一个记录的地址偏移量被称为槽, 存放在该页的"页目录"中
        3.  在页中查找记录: 先通过二分法搜索"页目录"确定记录附近的槽, 在通过遍历槽所对应的组定位记录
     2. 页之间
        1. 页之间是按主键由小到大顺序组成的双向链表. 为方便查找, 也需为页建立目录, 该目录也会被存入上层页中. 当该上层页存满目录后会发生"页分裂", 因此还需要更高层的页来记录这两个目录页的位置, 以上这些页组成了一棵树, 叫B+树
        2. 页分裂: 插入数据, 如果超出页的大小, 就会发生移动, 大的往后移. 插入时, 主键有序比无序效率高很多, 原因就是可以避免大量页分裂造成的移动
        3. 在页之间查找记录: 目录项页中当然也有页目录, 查找也是二分组号+一组遍历, 最终找到对应的页号, 再在下层新页中不断重复

* 索引

  1. 索引概述

     1. mysql索引分为聚簇索引, 二级索引和联合索引
     2. 可以看出innodb建立索引就是建立B+树, 树的叶子节点存数据, 非叶子节点记录的都是目录项
     3. 查询时尽量使用索引覆盖, 避免使用*, 因为会增加回表

  2. 聚簇索引

     1. 树的叶子节点就是全部的数据, 这样的索引就是聚簇索引
     2. innodb优先采用用户定义的主键作为主键, 未设置则使用表中unique键作为主键, 如果也没有, 默认增加一个row_id隐藏列作为主键

  3. 二级索引

     我们也可以自己对目标列建立索引, 生成B+树, 大致结构不变, 但有以下几点不一样:

     1. 目录项页中每行记录的具体列名不再是"主键+页号", 而是变为"目标列+主键+页号"
     2. 页中, 页间也不是用主键值从小到大排序了, 而是对目标列从小到大排序, 当目标列相同时, 自动按主键从小到大排序. 查找时也是和上面一样, 当目标列有多个值相等时, 就会看主键
     3. 叶子节点存储的是"目标列+主键", 故查完只能找到主键值. 要获取那行的真正记录, 还需要拿主键值到聚簇索引所对应的B+树里去查找, 这个操作叫"回表". 为啥不放数据呢? 省内存

  4. 联合索引

     1. 和二级索引一样的, 只是页中每行的具体列名变成了"列1 + 列2 + .. + 主键 + 页号", 排序是也先按照列1, 列2, 列3...

  5. B+树的索引适用于

     1. 全值匹配
     2. 匹配最左边的列
     3. 匹配范围值
     4. 精确匹配左边列, 并范围匹配索引剩下列
     5. 排序/分组时也遵守上述规则

  6. 建立索引的原则

     1. 只为用于搜索, 排序, 分组条件的列创建索引
     2. 为"列基数大"的列创建索引, "列基数"指表中该列的不同值数量
     3. 可以只对字符串列的前缀建立索引
     4. 主键尽量用自增的, 避免插入数据时发生页分裂

* MyISAM引擎

  1. 没有事务
  2. 锁
     1. 一次获取所有所需的锁, 因此不会死锁
     2. MyISAM没有行锁, 执行select前会自动给涉及的表加读锁, 执行update, delete. insert前会自动给涉及的表加写锁, 不需要用户显示加锁
  3. 存储结构
     1. MyISAM数据存储到数据文件中, 每条记录都对应着一个行号
     2. 建立索引的时候, 叶子节点页中行存的是"主键值+行号", 所以其不像innodb可以马上拿到记录, 其需要去数据文件中读取对应行才能拿到, 这个操作叫"回表"
     3. 因此MyISAM都是二级索引, 没有聚簇索引. 优点是当其使用非主键列查时, 因为存储的是行号, 相比innodb在相同场景下会更快. 所以Innodb的索引即是数据, MyISAM则是索引和数据明确分开

* 增加认识

  1. 存储过程: 预编译的SQL语句, 优点: 1) 避免传递SQL, 使用效率高, 2) 避免对表的直接访问, 权限控制; 缺点: 互联网因迭代快, 写在服务层其实更好. 目前不建议使用

  2. varchar不是无限的, 取决于字符集, 一般是65536/字符集规定每个字符最大占用的字节数; char(10)与varchar(10)与int(10)区别

  3. 超大分页的优化

     * mysql中"limit offset, num", 是取出offset+num, 然后抛弃前offset条, 这样效率不高. 可以尝试用子查询优化: select * from A where id in (select id from A), 尽可能使用索引覆盖(只使用索引的查询, 没有回表操作).

     * 避免类似的请求

  4. char(10)与varchar(10)与int(10)区别: char效率高, 但废空间; int只是最大显示宽度, 与存储无关

  5. 慢查询优化: 1) 不要load不需要的列, 2) 加索引, 3) 分页

  6. 分表

     * 水平分表: 一张表中存储了大量几亿用户, 可以按照id分, 拆成几百张表, 每张表保持一百万记录
     * 垂直分表: 图书字段过多, 需要拆分些出去

  7. 三个范式(设计数据表结构需遵循的规则)

     第一范式: 每列不可再拆分

     第二范式: 非主键列完全依赖于主键, 而不是主键的一部分

     第三范式: 非主键列只依赖于主键, 不依赖于其他非主键, 即传递依赖

  8. drop, delete, truncate区别

     drop, truncate都是数据定义语句, 不能回滚, 不会触发相应的trigger, 执行完自动提交(不要用于事务中); delete是数据操作语句, 可以回滚, 会触发相应的trigger, 执行完不自动提交(可用于事务)

     drop, truncate都是删除表中所有数据, delete可以选择一定的范围; drop还会额外删除表的定义, 操作不会触发相应的trigger

     速度: drop>truncate>delete

  9. 平衡二叉树, B树, B+树

     * 平衡二叉树
     * B树: 特点(多路平衡树), 查找, 插入, 删除
     * B+树: 与B树的区别(每个节点关键字都有子树, 具体数据在根节点)

  10. MySQL单机最大1000QPS

